{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Tweet Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tweet Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to cheack whether \n",
    "def check_var(data, x):\n",
    "    try:\n",
    "        data[x]\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "CPU times: user 6.89 ms, sys: 4.52 ms, total: 11.4 ms\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#making mongoDB database and collection\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['mydatabase']\n",
    "\n",
    "want_drop = input()\n",
    "if(want_drop=='yes'): ## if type yes, then it will drop tweet table from mongodb to prepare new importing.\n",
    "    db.tweet.drop()\n",
    "    \n",
    "tweet = db['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelin directory '/Users/yelin/Downloads/corona-out-3/corona-out-3'\n",
    "#Mo 'C:/Users/maxmo/OneDrive/Desktop/Rutgers/Spring2020/Data Management/corona-out-2'\n",
    "# Hui Wang  file = '/Users/huiwang/Downloads/corona-out-2'\n",
    "file = '/Users/huiwang/Downloads/corona-out-3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 52s, sys: 6.07 s, total: 1min 58s\n",
      "Wall time: 18min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'id_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#id, user_id, created_at, text, retweet_count, favorite_count, reply_count, hashtags\n",
    "import json\n",
    "with open(file, 'r', encoding = 'utf8') as f1 :\n",
    "    for line in f1 :\n",
    "        try :\n",
    "            data = json.loads(line)\n",
    "        except :\n",
    "            continue\n",
    "        \n",
    "        hashtag = [] #to collect list of hashtags\n",
    "        \n",
    "        if (data['lang'] == 'en'):\n",
    "            \n",
    "            #case 1: check whether it is a retweet data or not\n",
    "            if (check_var(data, 'retweeted_status')) :\n",
    "\n",
    "                Created_at = pd.to_datetime(data['retweeted_status']['created_at']).strftime('%B %d, %Y, %r')\n",
    "                UserID = data['retweeted_status']['user']['id']\n",
    "                ID = data['retweeted_status']['id']\n",
    "                retweet_count = data['retweeted_status']['retweet_count']\n",
    "                favorite_count = data['retweeted_status']['favorite_count']\n",
    "                reply_count = data['retweeted_status']['reply_count']\n",
    "\n",
    "                #check whether there is extension version of that tweet or not        \n",
    "                if (check_var(data['retweeted_status'], 'extended_tweet')) :\n",
    "                    Text = data['retweeted_status']['extended_tweet']['full_text']\n",
    "                    for t in data['retweeted_status']['extended_tweet']['entities']['hashtags'] :\n",
    "                        hashtag.append(t['text'])                \n",
    "                else :\n",
    "                    Text = data['retweeted_status']['text']\n",
    "                    for t in data['retweeted_status']['entities']['hashtags'] :\n",
    "                        hashtag.append(t['text'])\n",
    "\n",
    "                #check whether it is retweet of quoted tweet or not\n",
    "                if (check_var(data['retweeted_status'], 'quoted_status')) :\n",
    "\n",
    "                    #check whether there is extension version of the original tweet or not \n",
    "                    if (check_var(data['retweeted_status']['quoted_status'], 'extended_tweet')) :\n",
    "                        Text = Text + ' || ' + data['retweeted_status']['quoted_status']['extended_tweet']['full_text']\n",
    "                        for t in data['retweeted_status']['quoted_status']['extended_tweet']['entities']['hashtags'] :\n",
    "                            hashtag.append(t['text'])                \n",
    "                    else :\n",
    "                        Text = Text + ' || ' + data['retweeted_status']['quoted_status']['text']\n",
    "                        for t in data['retweeted_status']['quoted_status']['entities']['hashtags'] :\n",
    "                            hashtag.append(t['text'])               \n",
    "\n",
    "            #case 2: check whether it is a quote tweet data or not\n",
    "            elif (check_var(data, 'quoted_status')) :\n",
    "                Created_at = pd.to_datetime(data['created_at']).strftime('%B %d, %Y, %r')\n",
    "                UserID = data['user']['id']\n",
    "                ID = data['id']\n",
    "                retweet_count = data['retweet_count']\n",
    "                favorite_count = data['favorite_count']\n",
    "                reply_count = data['reply_count']\n",
    "\n",
    "                #check whether there is extension version of that quote tweet or not \n",
    "                if(check_var(data, 'extended_tweet')) :\n",
    "                    Text = data['extended_tweet']['full_text'] + ' || ' \n",
    "                else:\n",
    "                    Text = data['text'] + ' || '\n",
    "\n",
    "                for t in data['entities']['hashtags'] :\n",
    "                    hashtag.append(t['text'])\n",
    "\n",
    "                #check whether there is extension version of the originl tweet or not \n",
    "                if (check_var(data['quoted_status'], 'extended_tweet')) :\n",
    "                    Text = Text + data['quoted_status']['extended_tweet']['full_text']\n",
    "                    for t in data['quoted_status']['extended_tweet']['entities']['hashtags'] :\n",
    "                        hashtag.append(t['text'])                \n",
    "                else:\n",
    "                    Text = Text + data['quoted_status']['text']\n",
    "                    for t in data['quoted_status']['entities']['hashtags'] :\n",
    "                        hashtag.append(t['text'])\n",
    "\n",
    "            #if it does not belong to case 1 and case 2, it is an ordinary tweet data\n",
    "            else :\n",
    "                Created_at = pd.to_datetime(data['created_at']).strftime('%B %d, %Y, %r')\n",
    "                UserID = data['user']['id']\n",
    "                ID = data['id']\n",
    "                retweet_count = data['retweet_count']\n",
    "                favorite_count = data['favorite_count']\n",
    "                reply_count = data['reply_count']\n",
    "\n",
    "                #check whether there is extension version of that tweet or not  \n",
    "                if(check_var(data, 'extended_tweet')) :\n",
    "                    Text = data['extended_tweet']['full_text']\n",
    "                else :\n",
    "                    Text = data['text']\n",
    "\n",
    "                for t in data['entities']['hashtags'] :\n",
    "                    hashtag.append(t['text'])\n",
    "\n",
    "            tw = {'id' : ID,\n",
    "                  'user_id' : UserID,\n",
    "                  'created_at' : Created_at,\n",
    "                  'text' : Text,\n",
    "                  'retweet_count' : retweet_count,\n",
    "                  'favorite_count' : favorite_count,\n",
    "                  'reply_count' : reply_count,\n",
    "                  'hashtags': hashtag\n",
    "                 }\n",
    "\n",
    "            #if the data is already in our database, we update it \n",
    "            if (tweet.count_documents({'id' : tw['id']}) > 0) :\n",
    "                db.tweet.update_one({'id' : tw['id']},\n",
    "                                    {'$set' : {'retweet_count' : tw['retweet_count'],\n",
    "                                               'favorite_count' : tw['favorite_count'],\n",
    "                                               'reply_count' : tw['reply_count']}})\n",
    "            #if it is not, we insert it    \n",
    "            else :\n",
    "                tweet.insert_one(tw)\n",
    "            \n",
    "\n",
    "tweet.create_index([ ('id', 1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19465, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_table = pd.DataFrame(tweet.find())\n",
    "tweet_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# II. User Data Cleaning\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "##Creating the database\n",
    "conn = psycopg2.connect(\"dbname=postgres port=5432 user=postgres password=password\")\n",
    "conn.set_session(autocommit = True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "want_drop = input()\n",
    "if(want_drop=='yes'): ## if type yes, then it will drop database from postgreSQL to prepare new importing.\n",
    "    cur.execute(\"DROP DATABASE IF EXISTS twitter_users\" )\n",
    "    \n",
    "cur.execute(\"CREATE DATABASE twitter_users\" )\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the table\n",
    "conn = psycopg2.connect(\"dbname=twitter_users port=5432 user=postgres password=password\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE TABLE IF NOT EXISTS users_data( user_id varchar(50) PRIMARY KEY, name varchar(255), user_name varchar(255), verified_status boolean,followers_count integer,friends_count integer,statuses_count integer,user_location varchar(500),favourites_count integer);\" )\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_var(data,x):\n",
    "    try:\n",
    "        data[x]\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 s, sys: 13.8 s, total: 1min 6s\n",
      "Wall time: 12min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#This function takes the the variable inputs and stores it into a PostgreSQL database\n",
    "def store_data(user_id, name, user_name, verified_status, followers_count, friends_count, statuses_count, user_location, favourites_count):\n",
    "    conn = psycopg2.connect(\"dbname=twitter_users port=5432 user=postgres password=password\")\n",
    "    cur = conn.cursor()\n",
    "    insert_query = \"INSERT INTO users_data (user_id, name, user_name, verified_status, followers_count, friends_count, statuses_count, user_location, favourites_count) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s) ON CONFLICT (user_id) DO UPDATE SET verified_status=EXCLUDED.verified_status, followers_count=EXCLUDED.followers_count, friends_count=EXCLUDED.friends_count, statuses_count=EXCLUDED.statuses_count, user_location=EXCLUDED.user_location, favourites_count=EXCLUDED.favourites_count\"\n",
    "    cur.execute(insert_query, (user_id, name, user_name, verified_status, followers_count, friends_count, statuses_count, user_location,favourites_count))\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "# Decoding the JSON file\n",
    "with open(file, 'r', encoding = 'utf8') as f1:\n",
    "    for line in f1:\n",
    "        \n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if (data['lang'] == 'en'): # only \n",
    "            \n",
    "            if (check_var(data, 'retweeted_status')):\n",
    "\n",
    "                user_id = data['retweeted_status']['user']['id_str']\n",
    "                name = data['retweeted_status']['user']['name']\n",
    "                user_name = data['retweeted_status']['user']['screen_name']\n",
    "                verified_status = data['retweeted_status']['user']['verified']\n",
    "                followers_count = data['retweeted_status']['user']['followers_count']\n",
    "                friends_count = data['retweeted_status']['user']['friends_count']\n",
    "                statuses_count = data['retweeted_status']['user']['statuses_count']\n",
    "                user_location = data['retweeted_status']['user']['location']\n",
    "                favourites_count= data['retweeted_status']['user']['favourites_count']\n",
    "\n",
    "\n",
    "            else :\n",
    "                user_id = data['user']['id_str']\n",
    "                name = data['user']['name']\n",
    "                user_name = data['user']['screen_name']\n",
    "                verified_status = data['user']['verified']\n",
    "                followers_count = data['user']['followers_count']\n",
    "                friends_count = data['user']['friends_count']\n",
    "                statuses_count = data['user']['statuses_count']\n",
    "                user_location = data['user']['location']\n",
    "                favourites_count= data['user']['favourites_count']\n",
    "\n",
    "\n",
    "            #insert the data into the PostgreSQL database\n",
    "            store_data(user_id, name, user_name, verified_status, followers_count, friends_count, statuses_count, user_location, favourites_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=twitter_users port=5432 user=postgres password=password\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "# A function that takes in a PostgreSQL query and outputs a pandas database \n",
    "def create_pandas_table(sql_query, database = conn):\n",
    "    table = pd.read_sql_query(sql_query, database)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15673, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_table = create_pandas_table(\"SELECT * FROM users_data\")\n",
    "user_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# III. Searching Application\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install PySpark\n",
    "#!curl -O https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz\n",
    "#!tar -xvf spark-2.2.0-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure your python environment by uncommenting the line below.\n",
    "#!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Launch PySpark\n",
    "import os\n",
    "import findspark\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
    "findspark.init(\"spark-2.2.0-bin-hadoop2.7\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import components of SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Column, Row, functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the SparkSQL session which contains a basic Spark Context. This may take a few moments to launch the cluster of (typically 4 to 8 python jobs in the background). Note that you are running Spark locally (.master)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local[*]\")\n",
    "        .appName(\"SparkLecture694Example\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG tweet_table_spark = spark.createDataFrame(tweet_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG user_table_spark = spark.createDataFrame(user_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within the Tweet table, a user can get such as the most popular original tweet ranked by the retweet_count, favorite_count, and reply_count; \n",
    "# or the most popular hashtag ranked by aggregating the lists of hashtags among all tweets we collect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5ea4ac7b221c62f93908afc4</td>\n",
       "      <td>1238264431320215553</td>\n",
       "      <td>1100261477989126145</td>\n",
       "      <td>March 13, 2020, 12:43:40 AM</td>\n",
       "      <td>*corona virus enters my body*\\n\\nThe 4 Flintst...</td>\n",
       "      <td>237307</td>\n",
       "      <td>811062</td>\n",
       "      <td>1811</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5ea4ac32221c62f93908a913</td>\n",
       "      <td>1240334979701395458</td>\n",
       "      <td>1112592502727548928</td>\n",
       "      <td>March 18, 2020, 05:51:18 PM</td>\n",
       "      <td>When this Corona shit passes we have to promis...</td>\n",
       "      <td>181584</td>\n",
       "      <td>764405</td>\n",
       "      <td>1595</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5ea4abce221c62f939089d91</td>\n",
       "      <td>1237436114887041024</td>\n",
       "      <td>1131227186</td>\n",
       "      <td>March 10, 2020, 05:52:14 PM</td>\n",
       "      <td>THIS MAN IS A GENIUS he figured out the Corona...</td>\n",
       "      <td>179037</td>\n",
       "      <td>515867</td>\n",
       "      <td>1578</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5ea4acd0221c62f93908b562</td>\n",
       "      <td>1239689136358985729</td>\n",
       "      <td>728371324184301568</td>\n",
       "      <td>March 16, 2020, 11:04:57 PM</td>\n",
       "      <td>“corona time “😭😭😭😭 https://t.co/iXBMHVcFoY</td>\n",
       "      <td>132003</td>\n",
       "      <td>422685</td>\n",
       "      <td>1516</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5ea4afc3221c62f93908d441</td>\n",
       "      <td>1242137430322446344</td>\n",
       "      <td>716432228</td>\n",
       "      <td>March 23, 2020, 05:13:35 PM</td>\n",
       "      <td>This is Dr. Usama Riaz. He spent past weeks sc...</td>\n",
       "      <td>119601</td>\n",
       "      <td>331618</td>\n",
       "      <td>4876</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   id              user_id  \\\n",
       "0  5ea4ac7b221c62f93908afc4  1238264431320215553  1100261477989126145   \n",
       "1  5ea4ac32221c62f93908a913  1240334979701395458  1112592502727548928   \n",
       "2  5ea4abce221c62f939089d91  1237436114887041024           1131227186   \n",
       "3  5ea4acd0221c62f93908b562  1239689136358985729   728371324184301568   \n",
       "4  5ea4afc3221c62f93908d441  1242137430322446344            716432228   \n",
       "\n",
       "                    created_at  \\\n",
       "0  March 13, 2020, 12:43:40 AM   \n",
       "1  March 18, 2020, 05:51:18 PM   \n",
       "2  March 10, 2020, 05:52:14 PM   \n",
       "3  March 16, 2020, 11:04:57 PM   \n",
       "4  March 23, 2020, 05:13:35 PM   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  *corona virus enters my body*\\n\\nThe 4 Flintst...         237307   \n",
       "1  When this Corona shit passes we have to promis...         181584   \n",
       "2  THIS MAN IS A GENIUS he figured out the Corona...         179037   \n",
       "3         “corona time “😭😭😭😭 https://t.co/iXBMHVcFoY         132003   \n",
       "4  This is Dr. Usama Riaz. He spent past weeks sc...         119601   \n",
       "\n",
       "   favorite_count  reply_count hashtags  \n",
       "0          811062         1811       []  \n",
       "1          764405         1595       []  \n",
       "2          515867         1578       []  \n",
       "3          422685         1516       []  \n",
       "4          331618         4876       []  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using MongoDB\n",
    "# most popular original tweet ranked by the retweet_count\n",
    "pop_retweet = pd.DataFrame(tweet.find().sort(\"retweet_count\",-1))\n",
    "pop_retweet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5ea4ac7b221c62f93908afc4</td>\n",
       "      <td>1238264431320215553</td>\n",
       "      <td>1100261477989126145</td>\n",
       "      <td>March 13, 2020, 12:43:40 AM</td>\n",
       "      <td>*corona virus enters my body*\\n\\nThe 4 Flintst...</td>\n",
       "      <td>237307</td>\n",
       "      <td>811062</td>\n",
       "      <td>1811</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5ea4ac32221c62f93908a913</td>\n",
       "      <td>1240334979701395458</td>\n",
       "      <td>1112592502727548928</td>\n",
       "      <td>March 18, 2020, 05:51:18 PM</td>\n",
       "      <td>When this Corona shit passes we have to promis...</td>\n",
       "      <td>181584</td>\n",
       "      <td>764405</td>\n",
       "      <td>1595</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5ea4abce221c62f939089d91</td>\n",
       "      <td>1237436114887041024</td>\n",
       "      <td>1131227186</td>\n",
       "      <td>March 10, 2020, 05:52:14 PM</td>\n",
       "      <td>THIS MAN IS A GENIUS he figured out the Corona...</td>\n",
       "      <td>179037</td>\n",
       "      <td>515867</td>\n",
       "      <td>1578</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5ea4acd0221c62f93908b562</td>\n",
       "      <td>1239689136358985729</td>\n",
       "      <td>728371324184301568</td>\n",
       "      <td>March 16, 2020, 11:04:57 PM</td>\n",
       "      <td>“corona time “😭😭😭😭 https://t.co/iXBMHVcFoY</td>\n",
       "      <td>132003</td>\n",
       "      <td>422685</td>\n",
       "      <td>1516</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5ea4afc3221c62f93908d441</td>\n",
       "      <td>1242137430322446344</td>\n",
       "      <td>716432228</td>\n",
       "      <td>March 23, 2020, 05:13:35 PM</td>\n",
       "      <td>This is Dr. Usama Riaz. He spent past weeks sc...</td>\n",
       "      <td>119601</td>\n",
       "      <td>331618</td>\n",
       "      <td>4876</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   id              user_id  \\\n",
       "0  5ea4ac7b221c62f93908afc4  1238264431320215553  1100261477989126145   \n",
       "1  5ea4ac32221c62f93908a913  1240334979701395458  1112592502727548928   \n",
       "2  5ea4abce221c62f939089d91  1237436114887041024           1131227186   \n",
       "3  5ea4acd0221c62f93908b562  1239689136358985729   728371324184301568   \n",
       "4  5ea4afc3221c62f93908d441  1242137430322446344            716432228   \n",
       "\n",
       "                    created_at  \\\n",
       "0  March 13, 2020, 12:43:40 AM   \n",
       "1  March 18, 2020, 05:51:18 PM   \n",
       "2  March 10, 2020, 05:52:14 PM   \n",
       "3  March 16, 2020, 11:04:57 PM   \n",
       "4  March 23, 2020, 05:13:35 PM   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  *corona virus enters my body*\\n\\nThe 4 Flintst...         237307   \n",
       "1  When this Corona shit passes we have to promis...         181584   \n",
       "2  THIS MAN IS A GENIUS he figured out the Corona...         179037   \n",
       "3         “corona time “😭😭😭😭 https://t.co/iXBMHVcFoY         132003   \n",
       "4  This is Dr. Usama Riaz. He spent past weeks sc...         119601   \n",
       "\n",
       "   favorite_count  reply_count hashtags  \n",
       "0          811062         1811       []  \n",
       "1          764405         1595       []  \n",
       "2          515867         1578       []  \n",
       "3          422685         1516       []  \n",
       "4          331618         4876       []  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using MongoDB \n",
    "# most popular original tweet ranked by the retweet_count, reply_count, and favorite_count \n",
    "pop_hottest = pd.DataFrame(tweet.find().sort([(\"retweet_count\",-1),(\"reply_count\",-1),(\"favorite_count\",-1)]))\n",
    "pop_hottest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-08c800b60da3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-08c800b60da3>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    reduce: function( curr, result ){},\u001b[0m\n\u001b[0m                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# using MongoDB \n",
    "# the most single popular hashtag ranked by aggregating the lists of hashtags\n",
    "pop_hashtags = db.tweet.group(\n",
    "   {\n",
    "     key: { user_id: 1, hashtags: 1 },\n",
    "     reduce: function( curr, result ){},\n",
    "     initial: { }\n",
    "   }\n",
    ")\n",
    "\n",
    "pop_hashtags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the user table, a user can get such as the most active verified user ranked by statuses_count; \n",
    "# most popular user ranked by followers_count, friends_count, and favourites_count;\n",
    "# or the most active location ranked by tweets count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>verified_status</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>favourites_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>47596019</td>\n",
       "      <td>Liputan6.com</td>\n",
       "      <td>liputan6dotcom</td>\n",
       "      <td>True</td>\n",
       "      <td>3687560</td>\n",
       "      <td>693</td>\n",
       "      <td>1381273</td>\n",
       "      <td>Jakarta Indonesia</td>\n",
       "      <td>7062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16973333</td>\n",
       "      <td>The Independent</td>\n",
       "      <td>Independent</td>\n",
       "      <td>True</td>\n",
       "      <td>3202840</td>\n",
       "      <td>1146</td>\n",
       "      <td>976895</td>\n",
       "      <td>London, England</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>378809160</td>\n",
       "      <td>𝔾𝕀𝔻𝕀𝕋ℝ𝔸𝔽𝔽𝕀ℂ</td>\n",
       "      <td>Gidi_Traffic</td>\n",
       "      <td>True</td>\n",
       "      <td>1676895</td>\n",
       "      <td>5826</td>\n",
       "      <td>922265</td>\n",
       "      <td>Everywhere</td>\n",
       "      <td>14478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2475273985</td>\n",
       "      <td>Paytm Care</td>\n",
       "      <td>Paytmcare</td>\n",
       "      <td>True</td>\n",
       "      <td>248675</td>\n",
       "      <td>15</td>\n",
       "      <td>861933</td>\n",
       "      <td>India</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15448383</td>\n",
       "      <td>Inquirer</td>\n",
       "      <td>inquirerdotnet</td>\n",
       "      <td>True</td>\n",
       "      <td>3076056</td>\n",
       "      <td>1852</td>\n",
       "      <td>858348</td>\n",
       "      <td>Makati City</td>\n",
       "      <td>34260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id             name       user_name  verified_status  \\\n",
       "0    47596019     Liputan6.com  liputan6dotcom             True   \n",
       "1    16973333  The Independent     Independent             True   \n",
       "2   378809160      𝔾𝕀𝔻𝕀𝕋ℝ𝔸𝔽𝔽𝕀ℂ    Gidi_Traffic             True   \n",
       "3  2475273985       Paytm Care       Paytmcare             True   \n",
       "4    15448383         Inquirer  inquirerdotnet             True   \n",
       "\n",
       "   followers_count  friends_count  statuses_count      user_location  \\\n",
       "0          3687560            693         1381273  Jakarta Indonesia   \n",
       "1          3202840           1146          976895    London, England   \n",
       "2          1676895           5826          922265         Everywhere   \n",
       "3           248675             15          861933              India   \n",
       "4          3076056           1852          858348        Makati City   \n",
       "\n",
       "   favourites_count  \n",
       "0              7062  \n",
       "1                 3  \n",
       "2             14478  \n",
       "3               402  \n",
       "4             34260  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using SQL\n",
    "# the most active verified user ranked by statuses_count\n",
    "active_user = create_pandas_table(\"SELECT * FROM users_data WHERE verified_status='True' ORDER BY statuses_count DESC\")\n",
    "active_user.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM (SELECT user_id, name, user_location, sum(followers_count+friends_count+favourites_count) as likes FROM users_data ORDER BY likes DESC) WHERE verified_status='True' ': subquery in FROM must have an alias\nLINE 1: SELECT * FROM (SELECT user_id, name, user_location, sum(foll...\n                      ^\nHINT:  For example, FROM (SELECT ...) [AS] foo.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSyntaxError\u001b[0m: subquery in FROM must have an alias\nLINE 1: SELECT * FROM (SELECT user_id, name, user_location, sum(foll...\n                      ^\nHINT:  For example, FROM (SELECT ...) [AS] foo.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-800947b9f980>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# using SQL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the most popular user ranked by followers_count, friends_count, and favourites_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpop_user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_pandas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM (SELECT user_id, name, user_location, sum(followers_count+friends_count+favourites_count) as likes FROM users_data ORDER BY likes DESC) WHERE verified_status='True' \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpop_user\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-123227f0e47e>\u001b[0m in \u001b[0;36mcreate_pandas_table\u001b[0;34m(sql_query, database)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# A function that takes in a PostgreSQL query and outputs a pandas database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_pandas_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m                 \u001b[0;34m\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m             )\n\u001b[0;32m-> 1610\u001b[0;31m             \u001b[0mraise_with_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36mraise_with_traceback\u001b[0;34m(exc, traceback)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEllipsis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m                 \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM (SELECT user_id, name, user_location, sum(followers_count+friends_count+favourites_count) as likes FROM users_data ORDER BY likes DESC) WHERE verified_status='True' ': subquery in FROM must have an alias\nLINE 1: SELECT * FROM (SELECT user_id, name, user_location, sum(foll...\n                      ^\nHINT:  For example, FROM (SELECT ...) [AS] foo.\n"
     ]
    }
   ],
   "source": [
    "# using SQL\n",
    "# the most popular user ranked by followers_count, friends_count, and favourites_count\n",
    "pop_user = create_pandas_table(\"SELECT * FROM (SELECT user_id, name, user_location, sum(followers_count+friends_count+favourites_count) as likes FROM users_data ORDER BY likes DESC) WHERE verified_status='True' \")\n",
    "pop_user.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using SQL\n",
    "# the most active location ranked by tweets count\n",
    "pop_location = create_pandas_table(\"SELECT * FROM users_data WHERE verified_status='True' ORDER BY statuses_count DESC\")\n",
    "pop_location.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: user_table; line 3 pos 9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mspark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o22.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: user_table; line 3 pos 9\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:643)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:595)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:625)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:618)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:61)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:618)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:564)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:85)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:82)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:82)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:74)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:74)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:69)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:67)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:50)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:66)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:623)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.base/java.lang.Thread.run(Thread.java:835)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-da5eab7eb234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mFROM\u001b[0m \u001b[0muser_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSORT\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mstatuses_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \"\"\").toPandas()\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \"\"\"\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mspark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: user_table; line 3 pos 9'"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, statuses_count\n",
    "    FROM user_table\n",
    "    SORT BY statuses_count\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the tweet table and user table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When a user searches for a keyword or hashtag in the Tweet table, the results will show all the original tweets \n",
    "# that contain it. We can rank it by number of retweets, number of favorites, number of replies, or sum of them to \n",
    "# find the most popular tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also link the results with the user table to find out the corresponding users \n",
    "# who tweet them and rank the results by the number of followers, number of friends, number of statuses, \n",
    "# number of favorites or combination of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also save the location information of users in the user table, even though it is self-reported and users \n",
    "# can choose whether they want to register or not. We still plan to set the related search in our application. \n",
    "\n",
    "# A user can search for the most preferred location ranked by amount of twitter users. \n",
    "# When a user searches a hashtag, the results can show the most active location related to the hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
