{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Tweet Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tweet Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to cheack whether \n",
    "def check_var(data, x):\n",
    "    try:\n",
    "        data[x]\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making mongoDB database and collection\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['mydatabase']\n",
    "db.tweet.drop()\n",
    "tweet = db['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary methods from tweepy library\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yelin directory '/Users/yelin/Downloads/corona-out-2/corona-out-2'\n",
    "#Mo 'C:/Users/maxmo/OneDrive/Desktop/Rutgers/Spring2020/Data Management/corona-out-2'\n",
    "# Hui Wang  file = '/Users/huiwang/Downloads/corona-out-2'\n",
    "file = '/Users/huiwang/Downloads/corona-out-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.4 s, sys: 2.08 s, total: 39.5 s\n",
      "Wall time: 3min 36s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'id_1'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#id, user_id, created_at, text, retweet_count, favorite_count, reply_count, hashtags\n",
    "import json\n",
    "with open(file, 'r', encoding = 'utf8') as f1 :\n",
    "    for line in f1 :\n",
    "        try :\n",
    "            data = json.loads(line)\n",
    "        except :\n",
    "            continue\n",
    "        \n",
    "        hashtag = [] #to collect list of hashtags\n",
    "        \n",
    "        if (data['lang'] == 'en'):\n",
    "            iseng = True\n",
    "        else:\n",
    "            iseng = False\n",
    "        \n",
    "        #case 1: check whether it is a retweet data or not\n",
    "        if (check_var(data, 'retweeted_status')) :\n",
    "            \n",
    "            Created_at = pd.to_datetime(data['retweeted_status']['created_at']).strftime('%B %d, %Y, %r')\n",
    "            UserID = data['retweeted_status']['user']['id']\n",
    "            ID = data['retweeted_status']['id']\n",
    "            retweet_count = data['retweeted_status']['retweet_count']\n",
    "            favorite_count = data['retweeted_status']['favorite_count']\n",
    "            reply_count = data['retweeted_status']['reply_count']\n",
    "            \n",
    "            #check whether there is extension version of that tweet or not        \n",
    "            if (check_var(data['retweeted_status'], 'extended_tweet')) :\n",
    "                Text = data['retweeted_status']['extended_tweet']['full_text']\n",
    "                for t in data['retweeted_status']['extended_tweet']['entities']['hashtags'] :\n",
    "                    hashtag.append(t['text'])                \n",
    "            else :\n",
    "                Text = data['retweeted_status']['text']\n",
    "                for t in data['retweeted_status']['entities']['hashtags'] :\n",
    "                    hashtag.append(t['text'])\n",
    "                    \n",
    "            #check whether it is retweet of quoted tweet or not\n",
    "            if (check_var(data['retweeted_status'], 'quoted_status')) :\n",
    "                \n",
    "                #check whether there is extension version of the original tweet or not \n",
    "                if (check_var(data['retweeted_status']['quoted_status'], 'extended_tweet')) :\n",
    "                    Text = Text + ' || ' + data['retweeted_status']['quoted_status']['extended_tweet']['full_text']\n",
    "                    for t in data['retweeted_status']['quoted_status']['extended_tweet']['entities']['hashtags'] :\n",
    "                        hashtag.append(t['text'])                \n",
    "                else :\n",
    "                    Text = Text + ' || ' + data['retweeted_status']['quoted_status']['text']\n",
    "                    for t in data['retweeted_status']['quoted_status']['entities']['hashtags'] :\n",
    "                        hashtag.append(t['text'])               \n",
    "        \n",
    "        #case 2: check whether it is a quote tweet data or not\n",
    "        elif (check_var(data, 'quoted_status')) :\n",
    "            Created_at = pd.to_datetime(data['created_at']).strftime('%B %d, %Y, %r')\n",
    "            UserID = data['user']['id']\n",
    "            ID = data['id']\n",
    "            retweet_count = data['retweet_count']\n",
    "            favorite_count = data['favorite_count']\n",
    "            reply_count = data['reply_count']\n",
    "            \n",
    "            #check whether there is extension version of that quote tweet or not \n",
    "            if(check_var(data, 'extended_tweet')) :\n",
    "                Text = data['extended_tweet']['full_text'] + ' || ' \n",
    "            else:\n",
    "                Text = data['text'] + ' || '\n",
    "            \n",
    "            for t in data['entities']['hashtags'] :\n",
    "                hashtag.append(t['text'])\n",
    "            \n",
    "            #check whether there is extension version of the originl tweet or not \n",
    "            if (check_var(data['quoted_status'], 'extended_tweet')) :\n",
    "                Text = Text + data['quoted_status']['extended_tweet']['full_text']\n",
    "                for t in data['quoted_status']['extended_tweet']['entities']['hashtags'] :\n",
    "                    hashtag.append(t['text'])                \n",
    "            else:\n",
    "                Text = Text + data['quoted_status']['text']\n",
    "                for t in data['quoted_status']['entities']['hashtags'] :\n",
    "                    hashtag.append(t['text'])\n",
    "        \n",
    "        #if it does not belong to case 1 and case 2, it is an ordinary tweet data\n",
    "        else :\n",
    "            Created_at = pd.to_datetime(data['created_at']).strftime('%B %d, %Y, %r')\n",
    "            UserID = data['user']['id']\n",
    "            ID = data['id']\n",
    "            retweet_count = data['retweet_count']\n",
    "            favorite_count = data['favorite_count']\n",
    "            reply_count = data['reply_count']\n",
    "            \n",
    "            #check whether there is extension version of that tweet or not  \n",
    "            if(check_var(data, 'extended_tweet')) :\n",
    "                Text = data['extended_tweet']['full_text']\n",
    "            else :\n",
    "                Text = data['text']\n",
    "                \n",
    "            for t in data['entities']['hashtags'] :\n",
    "                hashtag.append(t['text'])\n",
    "        \n",
    "        tw = {'id' : ID,\n",
    "              'user_id' : UserID,\n",
    "              'created_at' : Created_at,\n",
    "              'text' : Text,\n",
    "              'retweet_count' : retweet_count,\n",
    "              'favorite_count' : favorite_count,\n",
    "              'reply_count' : reply_count,\n",
    "              'hashtags': hashtag,\n",
    "              'isenglish' : iseng\n",
    "             }\n",
    "        \n",
    "        #if the data is already in our database, we update it \n",
    "        if (tweet.count_documents({'id' : tw['id']}) > 0) :\n",
    "            db.tweet.update_one({'id' : tw['id']},\n",
    "                                {'$set' : {'retweet_count' : tw['retweet_count'],\n",
    "                                           'favorite_count' : tw['favorite_count'],\n",
    "                                           'reply_count' : tw['reply_count']}})\n",
    "        #if it is not, we insert it    \n",
    "        else :\n",
    "            tweet.insert_one(tw)\n",
    "            \n",
    "\n",
    "tweet.create_index([ ('id', 1) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>isenglish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5ea3a0b1d4faf2424b735f3d</td>\n",
       "      <td>1249378751349231616</td>\n",
       "      <td>16144221</td>\n",
       "      <td>April 12, 2020, 04:48:01 PM</td>\n",
       "      <td>wishing death on people is weirdo behavior. ||...</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5ea3a0b1d4faf2424b735f3e</td>\n",
       "      <td>1249397541596286979</td>\n",
       "      <td>1087735689091928064</td>\n",
       "      <td>April 12, 2020, 06:02:41 PM</td>\n",
       "      <td>In Turkey, there are 300 thousand prisoners an...</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>[COVID19InTurkeysPrisons]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5ea3a0b1d4faf2424b735f3f</td>\n",
       "      <td>1249326224964345857</td>\n",
       "      <td>268218622</td>\n",
       "      <td>April 12, 2020, 01:19:18 PM</td>\n",
       "      <td>Thank You Sir !!\\nReally thankful for encourag...</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>[BSNL]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5ea3a0b1d4faf2424b735f40</td>\n",
       "      <td>1249403114614075400</td>\n",
       "      <td>1193535233242664960</td>\n",
       "      <td>April 12, 2020, 06:24:49 PM</td>\n",
       "      <td>Turkey is so stubborn to change their mind, th...</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>[COVID19InTurkeysPrisons]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5ea3a0b1d4faf2424b735f41</td>\n",
       "      <td>1249316363681910784</td>\n",
       "      <td>14135350</td>\n",
       "      <td>April 12, 2020, 12:40:06 PM</td>\n",
       "      <td>This image.\\nThis quote.\\n\\n‚ÄúOne of the reason...</td>\n",
       "      <td>3319</td>\n",
       "      <td>6875</td>\n",
       "      <td>230</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5ea3a0b1d4faf2424b735f42</td>\n",
       "      <td>1249403770360016896</td>\n",
       "      <td>988174833849634816</td>\n",
       "      <td>April 12, 2020, 06:27:26 PM</td>\n",
       "      <td>SER√Å APENAS COINCID√äNCIA?\\n\\nAp√≥s escudo do Re...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   id              user_id  \\\n",
       "0  5ea3a0b1d4faf2424b735f3d  1249378751349231616             16144221   \n",
       "1  5ea3a0b1d4faf2424b735f3e  1249397541596286979  1087735689091928064   \n",
       "2  5ea3a0b1d4faf2424b735f3f  1249326224964345857            268218622   \n",
       "3  5ea3a0b1d4faf2424b735f40  1249403114614075400  1193535233242664960   \n",
       "4  5ea3a0b1d4faf2424b735f41  1249316363681910784             14135350   \n",
       "5  5ea3a0b1d4faf2424b735f42  1249403770360016896   988174833849634816   \n",
       "\n",
       "                    created_at  \\\n",
       "0  April 12, 2020, 04:48:01 PM   \n",
       "1  April 12, 2020, 06:02:41 PM   \n",
       "2  April 12, 2020, 01:19:18 PM   \n",
       "3  April 12, 2020, 06:24:49 PM   \n",
       "4  April 12, 2020, 12:40:06 PM   \n",
       "5  April 12, 2020, 06:27:26 PM   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  wishing death on people is weirdo behavior. ||...             24   \n",
       "1  In Turkey, there are 300 thousand prisoners an...             23   \n",
       "2  Thank You Sir !!\\nReally thankful for encourag...             18   \n",
       "3  Turkey is so stubborn to change their mind, th...             26   \n",
       "4  This image.\\nThis quote.\\n\\n‚ÄúOne of the reason...           3319   \n",
       "5  SER√Å APENAS COINCID√äNCIA?\\n\\nAp√≥s escudo do Re...              5   \n",
       "\n",
       "   favorite_count  reply_count                   hashtags  isenglish  \n",
       "0              50            1                         []       True  \n",
       "1              10            1  [COVID19InTurkeysPrisons]       True  \n",
       "2              24            0                     [BSNL]       True  \n",
       "3              13            0  [COVID19InTurkeysPrisons]       True  \n",
       "4            6875          230                         []       True  \n",
       "5               7            0                         []      False  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_table = pd.DataFrame(tweet.find())\n",
    "tweet_table.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# II. User Data Cleaning\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## User Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateDatabase",
     "evalue": "database \"twitter_users\" already exists\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDuplicateDatabase\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-a57715c3643b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE DATABASE twitter_users\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDuplicateDatabase\u001b[0m: database \"twitter_users\" already exists\n"
     ]
    }
   ],
   "source": [
    "##Creating the database\n",
    "conn = psycopg2.connect(\"dbname=postgres port=5432 user=postgres password=password\")\n",
    "conn.set_session(autocommit = True)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE DATABASE twitter_users\" )\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the table\n",
    "conn = psycopg2.connect(\"dbname=twitter_users port=5432 user=postgres password=password\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE TABLE IF NOT EXISTS users_data( user_id varchar(50) PRIMARY KEY, name varchar(255), user_name varchar(255), verified_status boolean,followers_count integer,friends_count integer,statuses_count integer,user_location varchar(500),favourites_count integer);\" )\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_var(data,x):\n",
    "    try:\n",
    "        data[x]\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.6 s, sys: 8.8 s, total: 23.4 s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#This function takes the the variable inputs and stores it into a PostgreSQL database\n",
    "def store_data(user_id, name, user_name, verified_status, followers_count, friends_count, statuses_count, user_location, favourites_count):\n",
    "    conn = psycopg2.connect(\"dbname=twitter_users port=5432 user=postgres password=password\")\n",
    "    cur = conn.cursor()\n",
    "    insert_query = \"INSERT INTO users_data (user_id, name, user_name, verified_status, followers_count, friends_count, statuses_count, user_location, favourites_count) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s) ON CONFLICT (user_id) DO UPDATE SET verified_status=EXCLUDED.verified_status, followers_count=EXCLUDED.followers_count, friends_count=EXCLUDED.friends_count, statuses_count=EXCLUDED.statuses_count, user_location=EXCLUDED.user_location, favourites_count=EXCLUDED.favourites_count\"\n",
    "    cur.execute(insert_query, (user_id, name, user_name, verified_status, followers_count, friends_count, statuses_count, user_location,favourites_count))\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "# Decoding the JSON file\n",
    "with open(file, 'r', encoding = 'utf8') as f1:\n",
    "    for line in f1:\n",
    "        \n",
    "        try:\n",
    "            data = json.loads(line)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if (check_var(data, 'retweeted_status')):\n",
    "            \n",
    "            user_id = data['retweeted_status']['user']['id_str']\n",
    "            name = data['retweeted_status']['user']['name']\n",
    "            user_name = data['retweeted_status']['user']['screen_name']\n",
    "            verified_status = data['retweeted_status']['user']['verified']\n",
    "            followers_count = data['retweeted_status']['user']['followers_count']\n",
    "            friends_count = data['retweeted_status']['user']['friends_count']\n",
    "            statuses_count = data['retweeted_status']['user']['statuses_count']\n",
    "            user_location = data['retweeted_status']['user']['location']\n",
    "            favourites_count= data['retweeted_status']['user']['favourites_count']\n",
    "            \n",
    "           \n",
    "        else :\n",
    "            user_id = data['user']['id_str']\n",
    "            name = data['user']['name']\n",
    "            user_name = data['user']['screen_name']\n",
    "            verified_status = data['user']['verified']\n",
    "            followers_count = data['user']['followers_count']\n",
    "            friends_count = data['user']['friends_count']\n",
    "            statuses_count = data['user']['statuses_count']\n",
    "            user_location = data['user']['location']\n",
    "            favourites_count= data['user']['favourites_count']\n",
    "            \n",
    "               \n",
    "        #insert the data into the PostgreSQL database\n",
    "        store_data(user_id, name, user_name, verified_status, followers_count, friends_count, statuses_count, user_location, favourites_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=twitter_users port=5432 user=postgres password=password\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "# A function that takes in a PostgreSQL query and outputs a pandas database \n",
    "def create_pandas_table(sql_query, database = conn):\n",
    "    table = pd.read_sql_query(sql_query, database)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>user_name</th>\n",
       "      <th>verified_status</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>user_location</th>\n",
       "      <th>favourites_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1002953971315585024</td>\n",
       "      <td>üéÇSehun Day!üéÇ</td>\n",
       "      <td>olalala94</td>\n",
       "      <td>False</td>\n",
       "      <td>935</td>\n",
       "      <td>1326</td>\n",
       "      <td>17952</td>\n",
       "      <td>exo.x1.mcnd</td>\n",
       "      <td>10889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2986689026</td>\n",
       "      <td>RC Shukl</td>\n",
       "      <td>RC_Shukl</td>\n",
       "      <td>False</td>\n",
       "      <td>8919</td>\n",
       "      <td>309</td>\n",
       "      <td>8136</td>\n",
       "      <td>New Delhi  (#‡§ó‡•ã‡§∞‡§ñ‡§™‡•Å‡§∞, #‡§Ø‡•Ç‡§™‡•Ä)</td>\n",
       "      <td>24414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1195760001731588096</td>\n",
       "      <td>Vinay Kamath</td>\n",
       "      <td>VinayKamath6</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>559</td>\n",
       "      <td>None</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1055885344736993280</td>\n",
       "      <td>no Comment</td>\n",
       "      <td>lastcavalry61</td>\n",
       "      <td>False</td>\n",
       "      <td>7090</td>\n",
       "      <td>6451</td>\n",
       "      <td>72763</td>\n",
       "      <td>None</td>\n",
       "      <td>87387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16144221</td>\n",
       "      <td>NUFF</td>\n",
       "      <td>nuffsaidny</td>\n",
       "      <td>False</td>\n",
       "      <td>17112</td>\n",
       "      <td>1515</td>\n",
       "      <td>2599</td>\n",
       "      <td>None</td>\n",
       "      <td>15790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>102766855</td>\n",
       "      <td>TouT Haiti</td>\n",
       "      <td>touthaiti</td>\n",
       "      <td>False</td>\n",
       "      <td>7239</td>\n",
       "      <td>2339</td>\n",
       "      <td>16747</td>\n",
       "      <td>New York</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id          name      user_name  verified_status  \\\n",
       "0  1002953971315585024  üéÇSehun Day!üéÇ      olalala94            False   \n",
       "1           2986689026      RC Shukl       RC_Shukl            False   \n",
       "2  1195760001731588096  Vinay Kamath   VinayKamath6            False   \n",
       "3  1055885344736993280    no Comment  lastcavalry61            False   \n",
       "4             16144221          NUFF     nuffsaidny            False   \n",
       "5            102766855    TouT Haiti      touthaiti            False   \n",
       "\n",
       "   followers_count  friends_count  statuses_count  \\\n",
       "0              935           1326           17952   \n",
       "1             8919            309            8136   \n",
       "2               10             18             559   \n",
       "3             7090           6451           72763   \n",
       "4            17112           1515            2599   \n",
       "5             7239           2339           16747   \n",
       "\n",
       "                  user_location  favourites_count  \n",
       "0                   exo.x1.mcnd             10889  \n",
       "1  New Delhi  (#‡§ó‡•ã‡§∞‡§ñ‡§™‡•Å‡§∞, #‡§Ø‡•Ç‡§™‡•Ä)             24414  \n",
       "2                          None               458  \n",
       "3                          None             87387  \n",
       "4                          None             15790  \n",
       "5                      New York                96  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_table = create_pandas_table(\"SELECT * FROM users_data \")\n",
    "user_table.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# III. Searching Application\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install PySpark\n",
    "#!curl -O https://d3kbcqa49mib13.cloudfront.net/spark-2.2.0-bin-hadoop2.7.tgz\n",
    "#!tar -xvf spark-2.2.0-bin-hadoop2.7.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure your python environment by uncommenting the line below.\n",
    "#!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Launch PySpark\n",
    "import os\n",
    "import findspark\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
    "findspark.init(\"spark-2.2.0-bin-hadoop2.7\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import components of SparkSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Column, Row, functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the SparkSQL session which contains a basic Spark Context. This may take a few moments to launch the cluster of (typically 4 to 8 python jobs in the background). Note that you are running Spark locally (.master)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .master(\"local[*]\")\n",
    "        .appName(\"SparkLecture694Example\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG tweet_table_spark = spark.createDataFrame(tweet_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUG user_table_spark = spark.createDataFrame(user_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within the Tweet table, a user can get such as the most popular original tweet ranked by the retweet_count, favorite_count, and reply_count; \n",
    "# or the most popular hashtag ranked by aggregating the lists of hashtags among all tweets we collect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>isenglish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5ea3a186d4faf2424b7389e3</td>\n",
       "      <td>1235256530728972290</td>\n",
       "      <td>2863558530</td>\n",
       "      <td>March 04, 2020, 05:31:21 PM</td>\n",
       "      <td>ALERT‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\\nThe corona virus can be spread th...</td>\n",
       "      <td>298538</td>\n",
       "      <td>1128502</td>\n",
       "      <td>3269</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5ea3a0b4d4faf2424b7362a9</td>\n",
       "      <td>1237436114887041024</td>\n",
       "      <td>1131227186</td>\n",
       "      <td>March 10, 2020, 05:52:14 PM</td>\n",
       "      <td>THIS MAN IS A GENIUS he figured out the Corona...</td>\n",
       "      <td>179479</td>\n",
       "      <td>517027</td>\n",
       "      <td>1585</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5ea3a0b8d4faf2424b73656d</td>\n",
       "      <td>1239267360739074048</td>\n",
       "      <td>813286</td>\n",
       "      <td>March 15, 2020, 07:08:57 PM</td>\n",
       "      <td>Watch this. It shows why we should all do the ...</td>\n",
       "      <td>126614</td>\n",
       "      <td>388518</td>\n",
       "      <td>10081</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5ea3a137d4faf2424b7381da</td>\n",
       "      <td>1238612571193827335</td>\n",
       "      <td>29942414</td>\n",
       "      <td>March 13, 2020, 11:47:03 PM</td>\n",
       "      <td>If I gave you 100 skittles and told you 3 of t...</td>\n",
       "      <td>123900</td>\n",
       "      <td>598342</td>\n",
       "      <td>4472</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5ea3a145d4faf2424b738357</td>\n",
       "      <td>1238504604767223808</td>\n",
       "      <td>219582851</td>\n",
       "      <td>March 13, 2020, 04:38:02 PM</td>\n",
       "      <td>It wasn‚Äôt no corona till y‚Äôall started balanci...</td>\n",
       "      <td>103849</td>\n",
       "      <td>572346</td>\n",
       "      <td>534</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   id     user_id  \\\n",
       "0  5ea3a186d4faf2424b7389e3  1235256530728972290  2863558530   \n",
       "1  5ea3a0b4d4faf2424b7362a9  1237436114887041024  1131227186   \n",
       "2  5ea3a0b8d4faf2424b73656d  1239267360739074048      813286   \n",
       "3  5ea3a137d4faf2424b7381da  1238612571193827335    29942414   \n",
       "4  5ea3a145d4faf2424b738357  1238504604767223808   219582851   \n",
       "\n",
       "                    created_at  \\\n",
       "0  March 04, 2020, 05:31:21 PM   \n",
       "1  March 10, 2020, 05:52:14 PM   \n",
       "2  March 15, 2020, 07:08:57 PM   \n",
       "3  March 13, 2020, 11:47:03 PM   \n",
       "4  March 13, 2020, 04:38:02 PM   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  ALERT‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\\nThe corona virus can be spread th...         298538   \n",
       "1  THIS MAN IS A GENIUS he figured out the Corona...         179479   \n",
       "2  Watch this. It shows why we should all do the ...         126614   \n",
       "3  If I gave you 100 skittles and told you 3 of t...         123900   \n",
       "4  It wasn‚Äôt no corona till y‚Äôall started balanci...         103849   \n",
       "\n",
       "   favorite_count  reply_count hashtags  isenglish  \n",
       "0         1128502         3269       []       True  \n",
       "1          517027         1585       []       True  \n",
       "2          388518        10081       []       True  \n",
       "3          598342         4472       []       True  \n",
       "4          572346          534       []       True  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas \n",
    "# most popular original tweet ranked by the retweet_count\n",
    "pop_retweet = pd.DataFrame(tweet.find().sort(\"retweet_count\",-1))\n",
    "pop_retweet.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>isenglish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5ea3a186d4faf2424b7389e3</td>\n",
       "      <td>1235256530728972290</td>\n",
       "      <td>2863558530</td>\n",
       "      <td>March 04, 2020, 05:31:21 PM</td>\n",
       "      <td>ALERT‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\\nThe corona virus can be spread th...</td>\n",
       "      <td>298538</td>\n",
       "      <td>1128502</td>\n",
       "      <td>3269</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5ea3a0b4d4faf2424b7362a9</td>\n",
       "      <td>1237436114887041024</td>\n",
       "      <td>1131227186</td>\n",
       "      <td>March 10, 2020, 05:52:14 PM</td>\n",
       "      <td>THIS MAN IS A GENIUS he figured out the Corona...</td>\n",
       "      <td>179479</td>\n",
       "      <td>517027</td>\n",
       "      <td>1585</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5ea3a0b8d4faf2424b73656d</td>\n",
       "      <td>1239267360739074048</td>\n",
       "      <td>813286</td>\n",
       "      <td>March 15, 2020, 07:08:57 PM</td>\n",
       "      <td>Watch this. It shows why we should all do the ...</td>\n",
       "      <td>126614</td>\n",
       "      <td>388518</td>\n",
       "      <td>10081</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5ea3a137d4faf2424b7381da</td>\n",
       "      <td>1238612571193827335</td>\n",
       "      <td>29942414</td>\n",
       "      <td>March 13, 2020, 11:47:03 PM</td>\n",
       "      <td>If I gave you 100 skittles and told you 3 of t...</td>\n",
       "      <td>123900</td>\n",
       "      <td>598342</td>\n",
       "      <td>4472</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5ea3a145d4faf2424b738357</td>\n",
       "      <td>1238504604767223808</td>\n",
       "      <td>219582851</td>\n",
       "      <td>March 13, 2020, 04:38:02 PM</td>\n",
       "      <td>It wasn‚Äôt no corona till y‚Äôall started balanci...</td>\n",
       "      <td>103849</td>\n",
       "      <td>572346</td>\n",
       "      <td>534</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   id     user_id  \\\n",
       "0  5ea3a186d4faf2424b7389e3  1235256530728972290  2863558530   \n",
       "1  5ea3a0b4d4faf2424b7362a9  1237436114887041024  1131227186   \n",
       "2  5ea3a0b8d4faf2424b73656d  1239267360739074048      813286   \n",
       "3  5ea3a137d4faf2424b7381da  1238612571193827335    29942414   \n",
       "4  5ea3a145d4faf2424b738357  1238504604767223808   219582851   \n",
       "\n",
       "                    created_at  \\\n",
       "0  March 04, 2020, 05:31:21 PM   \n",
       "1  March 10, 2020, 05:52:14 PM   \n",
       "2  March 15, 2020, 07:08:57 PM   \n",
       "3  March 13, 2020, 11:47:03 PM   \n",
       "4  March 13, 2020, 04:38:02 PM   \n",
       "\n",
       "                                                text  retweet_count  \\\n",
       "0  ALERT‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\\nThe corona virus can be spread th...         298538   \n",
       "1  THIS MAN IS A GENIUS he figured out the Corona...         179479   \n",
       "2  Watch this. It shows why we should all do the ...         126614   \n",
       "3  If I gave you 100 skittles and told you 3 of t...         123900   \n",
       "4  It wasn‚Äôt no corona till y‚Äôall started balanci...         103849   \n",
       "\n",
       "   favorite_count  reply_count hashtags  isenglish  \n",
       "0         1128502         3269       []       True  \n",
       "1          517027         1585       []       True  \n",
       "2          388518        10081       []       True  \n",
       "3          598342         4472       []       True  \n",
       "4          572346          534       []       True  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using MongoDB \n",
    "# most popular original tweet ranked by the retweet_count, reply_count, and favorite_count \n",
    "pop_hottest = pd.DataFrame(tweet.find().sort([(\"retweet_count\",-1),(\"reply_count\",-1),(\"favorite_count\",-1)]))\n",
    "pop_hottest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_sql_query() missing 1 required positional argument: 'con'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-e6b94bedca8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# using SQL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the most popular hashtag ranked by aggregating the lists of hashtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpop_hashtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT user_id, text, count(*) as amount FROM tweet GROUP BY hashtags\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpop_hashtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_sql_query() missing 1 required positional argument: 'con'"
     ]
    }
   ],
   "source": [
    "# using SQL\n",
    "# the most popular hashtag ranked by aggregating the lists of hashtags\n",
    "pop_hashtags = pd.read_sql_query(\"SELECT user_id, text, count(*) as amount FROM tweet GROUP BY hashtags\")\n",
    "pop_hashtags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-105-b1258e029fac>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-105-b1258e029fac>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    spark.sql(SELECT text, retweet_count, favorite_count, reply_count FROM tweet SORT BY retweet_count)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#tweet_table.find().sort(col(\"retweet_count\".desc())).head(10)\n",
    "#tweet_table.orderBy(\"retweet_count\", ascending=False)\n",
    "spark.sql(SELECT text, retweet_count, favorite_count, reply_count FROM tweet SORT BY retweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the user table, a user can get such as the most active user ranked by statuses_count; \n",
    "# most popular user ranked by followers_count, friends_count, and favourites_count;\n",
    "# or the most active location ranked by tweets count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: user_table_spark; line 1 pos 14'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mspark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o22.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: user_table_spark; line 1 pos 14\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:643)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:595)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:625)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:618)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:61)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:618)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:564)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:85)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:82)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:82)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:74)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:74)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:69)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:67)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:50)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:66)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:623)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.base/java.lang.Thread.run(Thread.java:835)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-63eb56821751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m results = spark.sql(\n\u001b[0;32m----> 2\u001b[0;31m   \"SELECT * FROM user_table_spark\")\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \"\"\"\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mspark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: user_table_spark; line 1 pos 14'"
     ]
    }
   ],
   "source": [
    "results = spark.sql(\n",
    "  \"SELECT * FROM user_table_spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Table or view not found: user_table; line 3 pos 9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mspark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o22.sql.\n: org.apache.spark.sql.AnalysisException: Table or view not found: user_table; line 3 pos 9\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.org$apache$spark$sql$catalyst$analysis$Analyzer$ResolveRelations$$lookupTableFromCatalog(Analyzer.scala:643)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.resolveRelation(Analyzer.scala:595)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:625)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:618)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:62)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:61)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:306)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:187)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapChildren(TreeNode.scala:304)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:59)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:618)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:564)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:85)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:82)\n\tat scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)\n\tat scala.collection.immutable.List.foldLeft(List.scala:84)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:82)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:74)\n\tat scala.collection.immutable.List.foreach(List.scala:381)\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:74)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:69)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:67)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:50)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:66)\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:623)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:567)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.base/java.lang.Thread.run(Thread.java:835)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-da5eab7eb234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mFROM\u001b[0m \u001b[0muser_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mSORT\u001b[0m \u001b[0mBY\u001b[0m \u001b[0mstatuses_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \"\"\").toPandas()\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \"\"\"\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mspark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/Search-Application-on-Twitter/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Table or view not found: user_table; line 3 pos 9'"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT user_id, statuses_count\n",
    "    FROM user_table\n",
    "    SORT BY statuses_count\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the tweet table and user table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When a user searches for a keyword or hashtag in the Tweet table, the results will show all the original tweets \n",
    "# that contain it. We can rank it by number of retweets, number of favorites, number of replies, or sum of them to \n",
    "# find the most popular tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also link the results with the user table to find out the corresponding users \n",
    "# who tweet them and rank the results by the number of followers, number of friends, number of statuses, \n",
    "# number of favorites or combination of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also save the location information of users in the user table, even though it is self-reported and users \n",
    "# can choose whether they want to register or not. We still plan to set the related search in our application. \n",
    "\n",
    "# A user can search for the most preferred location ranked by amount of twitter users. \n",
    "# When a user searches a hashtag, the results can show the most active location related to the hashtag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
